// Copyright (c) 2021 Uber Technologies, Inc.
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
// THE SOFTWARE.

// This file was automatically generated by genny.
// Any changes will be lost if this file is regenerated.
// see https://github.com/mauricelam/genny

package aggregator

import (
	"fmt"
	"math"
	"sync"
	"time"

	raggregation "github.com/m3db/m3/src/aggregator/aggregation"
	"github.com/m3db/m3/src/metrics/metadata"
	"github.com/m3db/m3/src/metrics/metric/aggregated"
	"github.com/m3db/m3/src/metrics/metric/unaggregated"
	"github.com/m3db/m3/src/metrics/transformation"

	"github.com/willf/bitset"
)

//nolint:maligned
type timedGauge struct {
	// immutable data
	startAtNanos int64 // start time of an aggregation window

	// data read/written by incoming aggregation requests, guarded by the lock.
	// this lock only guards against other write requests. the flusher does not acquire this lock and instead acquires
	// the coarse grain entry lock.
	mu          *sync.Mutex
	dirty       bool
	closed      bool
	sourcesSeen map[uint32]*bitset.BitSet
	aggregation gaugeAggregation

	// data read/written only by the flusher, which does not need to be thread safe.
	// a snapshot of the aggregation values that is the input for the processing. reused across processing rounds.
	aggValues []float64
	// the output of the previous processing run for this timestamp. these are used to skip re-emitting values that have
	// not changed on resends. reused across processing rounds.
	prevConsumedValues []float64
	// a copy of the aggregation annotation. reused across processing rounds.
	annotation []byte
	flushed    bool
	expired    bool
}

func (ta *timedGauge) Release() {
	ta.startAtNanos = 0
	ta.aggValues = nil
	ta.prevConsumedValues = nil
	ta.annotation = nil
}

// GaugeElem is an element storing time-bucketed aggregations.
type GaugeElem struct {
	elemBase
	gaugeElemBase

	values []timedGauge // metric aggregations sorted by time in ascending order

	// internal consume state that does not need to be synchronized.
	toConsume []timedGauge // small buffer to avoid memory allocations during consumption
}

// NewGaugeElem returns a new GaugeElem.
func NewGaugeElem(data ElemData, opts Options) (*GaugeElem, error) {
	e := &GaugeElem{
		elemBase: newElemBase(opts),
		values:   make([]timedGauge, 0, defaultNumAggregations), // in most cases values will have two entries
	}
	if err := e.ResetSetData(data); err != nil {
		return nil, err
	}
	return e, nil
}

// MustNewGaugeElem returns a new GaugeElem and panics if an error occurs.
func MustNewGaugeElem(data ElemData, opts Options) *GaugeElem {
	elem, err := NewGaugeElem(data, opts)
	if err != nil {
		panic(fmt.Errorf("unable to create element: %v", err))
	}
	return elem
}

// ResetSetData resets the element and sets data.
func (e *GaugeElem) ResetSetData(data ElemData) error {
	useDefaultAggregation := data.AggTypes.IsDefault()
	if useDefaultAggregation {
		data.AggTypes = e.DefaultAggregationTypes(e.aggTypesOpts)
	}
	if err := e.elemBase.resetSetData(data, useDefaultAggregation); err != nil {
		return err
	}
	return e.gaugeElemBase.ResetSetData(e.aggTypesOpts, data.AggTypes, useDefaultAggregation)
}

// ResendEnabled returns true if resends are enabled for the element.
func (e *GaugeElem) ResendEnabled() bool {
	return e.resendEnabled
}

// AddUnion adds a metric value union at a given timestamp.
func (e *GaugeElem) AddUnion(timestamp time.Time, mu unaggregated.MetricUnion) error {
	alignedStart := timestamp.Truncate(e.sp.Resolution().Window).UnixNano()
	agg, eLock, err := e.findOrCreate(alignedStart, createAggregationOptions{})
	if err != nil {
		return err
	}
	agg.mu.Lock()
	if agg.closed {
		agg.mu.Unlock()
		eLock.Unlock()
		return errAggregationClosed
	}
	agg.aggregation.AddUnion(timestamp, mu)
	agg.dirty = true
	agg.mu.Unlock()
	eLock.Unlock()
	return nil
}

// AddValue adds a metric value at a given timestamp.
func (e *GaugeElem) AddValue(timestamp time.Time, value float64, annotation []byte) error {
	alignedStart := timestamp.Truncate(e.sp.Resolution().Window).UnixNano()
	agg, eLock, err := e.findOrCreate(alignedStart, createAggregationOptions{})
	if err != nil {
		return err
	}
	agg.mu.Lock()
	if agg.closed {
		agg.mu.Unlock()
		eLock.Unlock()
		return errAggregationClosed
	}
	agg.aggregation.Add(timestamp, value, annotation)
	agg.dirty = true
	agg.mu.Unlock()
	eLock.Unlock()
	return nil
}

// AddUnique adds a metric value from a given source at a given timestamp.
// If previous values from the same source have already been added to the
// same aggregation, the incoming value is discarded.
//nolint: dupl
func (e *GaugeElem) AddUnique(
	timestamp time.Time,
	metric aggregated.ForwardedMetric,
	metadata metadata.ForwardMetadata,
) error {
	alignedStart := timestamp.Truncate(e.sp.Resolution().Window).UnixNano()
	agg, eLock, err := e.findOrCreate(alignedStart, createAggregationOptions{initSourceSet: true})
	if err != nil {
		return err
	}
	agg.mu.Lock()
	if agg.closed {
		agg.mu.Unlock()
		eLock.Unlock()
		return errAggregationClosed
	}
	versionsSeen := agg.sourcesSeen[metadata.SourceID]
	if versionsSeen == nil {
		// N.B - these bitsets will be transitively cached through the cached sources seen.
		versionsSeen = bitset.New(defaultNumVersions)
		agg.sourcesSeen[metadata.SourceID] = versionsSeen
	}
	version := uint(metric.Version)
	if versionsSeen.Test(version) {
		agg.mu.Unlock()
		eLock.Unlock()
		return errDuplicateForwardingSource
	}
	versionsSeen.Set(version)

	if metric.Version > 0 {
		e.metrics.updatedValues.Inc(1)
		for i := range metric.Values {
			if err := agg.aggregation.UpdateVal(timestamp, metric.Values[i], metric.PrevValues[i]); err != nil {
				return err
			}
		}
	} else {
		for _, v := range metric.Values {
			agg.aggregation.Add(timestamp, v, metric.Annotation)
		}
	}

	agg.dirty = true
	agg.mu.Unlock()
	eLock.Unlock()
	return nil
}

// Consume consumes values before a given time and removes them from the element
// after they are consumed, returning whether the element can be collected after
// the consumption is completed.
// NB: Consume is not thread-safe and must be called within a single goroutine
// to avoid race conditions.
func (e *GaugeElem) Consume(
	targetNanos int64,
	isEarlierThanFn isEarlierThanFn,
	timestampNanosFn timestampNanosFn,
	flushLocalFn flushLocalMetricFn,
	flushForwardedFn flushForwardedMetricFn,
	onForwardedFlushedFn onForwardingElemFlushedFn,
) bool {
	resolution := e.sp.Resolution().Window
	e.Lock()
	if e.closed {
		e.Unlock()
		return false
	}
	e.toConsume = e.toConsume[:0]

	// Evaluate and GC expired items.
	var (
		prev           *timedGauge
		firstToConsume bool
	)
	valuesForConsideration := e.values
	e.values = e.values[:0]
	for i, value := range valuesForConsideration {
		if !isEarlierThanFn(value.startAtNanos, resolution, targetNanos) {
			e.values = append(e.values, value)
			continue
		}

		if !firstToConsume && i > 0 {
			prev = &valuesForConsideration[i-1]
		}
		firstToConsume = true

		value.expired = true
		if e.resendEnabled {
			// If resend is enabled, we only expire if the value is now outside the buffer past. It is safe to expire
			// since any metrics intended for this value are rejected for being too late.
			expiredNanos := targetNanos - e.bufferForPastTimedMetricFn(resolution).Nanoseconds()
			value.expired = value.startAtNanos < expiredNanos
		}

		// while holding the entry lock, copy any values that are guarded by the individual aggregations. this allows
		// the flusher to consume individual aggregations without requiring individual locks.
		for i, aType := range e.aggTypes {
			value.aggValues[i] = value.aggregation.ValueOf(aType)
		}
		value.annotation = raggregation.MaybeReplaceAnnotation(value.annotation, value.aggregation.Annotation())
		e.toConsume = append(e.toConsume, value)
		value.dirty = false
		value.flushed = true

		if value.expired {
			// expire anything that is read by the writers before we release the lock.
			// flush state is not released until after the processing round (below).
			value.closed = true
			value.aggregation.Close()
			if value.sourcesSeen != nil {
				// This is to make sure there aren't too many cached source sets taking up
				// too much space.
				if len(e.cachedSourceSets) < e.opts.MaxNumCachedSourceSets() {
					e.cachedSourceSets = append(e.cachedSourceSets, value.sourcesSeen)
				}
				value.sourcesSeen = nil
			}
		} else {
			// Keep item if not expired.
			e.values = append(e.values, value)
		}
	}
	canCollect := len(e.values) == 0 && e.tombstoned
	e.Unlock()

	var (
		cascadeDirty bool
	)
	// Process the aggregations that are ready for consumption.
	for i := range e.toConsume {
		timeNanos := timestampNanosFn(e.toConsume[i].startAtNanos, resolution)

		var (
			prevAgg       *timedGauge
			prevTimeNanos int64
		)
		if i > 0 {
			prevAgg = &e.toConsume[i-1]
			prevTimeNanos = timestampNanosFn(prevAgg.startAtNanos, resolution)
		} else if prev != nil {
			prevAgg = prev
			prevTimeNanos = timestampNanosFn(prevAgg.startAtNanos, resolution)
		}

		// if a previous timestamps was dirty, that value might impact a future derivative calculation, so
		// cascade the dirty bit to all succeeding values. there is a check later to not resend a value if it doesn't
		// change, so it's ok to optimistically mark dirty.
		if cascadeDirty || e.toConsume[i].dirty {
			cascadeDirty = e.processValueWithAggregationLock(
				timeNanos,
				prevTimeNanos,
				&e.toConsume[i],
				prevAgg,
				flushLocalFn,
				flushForwardedFn,
				resolution,
			)
		}
		if e.toConsume[i].expired {
			e.toConsume[i].Release()
		}
		prevTimeNanos = timeNanos
	}

	if e.parsedPipeline.HasRollup {
		forwardedAggregationKey, _ := e.ForwardedAggregationKey()
		onForwardedFlushedFn(e.onForwardedAggregationWrittenFn, forwardedAggregationKey)
	}

	return canCollect
}

// Close closes the element.
func (e *GaugeElem) Close() {
	e.Lock()
	if e.closed {
		e.Unlock()
		return
	}
	e.closed = true
	e.id = nil
	e.parsedPipeline = parsedPipeline{}
	e.writeForwardedMetricFn = nil
	e.onForwardedAggregationWrittenFn = nil
	for idx := range e.cachedSourceSets {
		e.cachedSourceSets[idx] = nil
	}
	e.cachedSourceSets = nil
	for idx := range e.values {
		// Close the underlying aggregation objects.
		e.values[idx].sourcesSeen = nil
		e.values[idx].aggregation.Close()
		e.values[idx].Release()
	}
	e.values = e.values[:0]
	e.gaugeElemBase.Close()
	aggTypesPool := e.aggTypesOpts.TypesPool()
	pool := e.ElemPool(e.opts)
	e.Unlock()

	// internal consumption state that doesn't need to be synchronized.
	e.toConsume = e.toConsume[:0]

	if !e.useDefaultAggregation {
		aggTypesPool.Put(e.aggTypes)
	}
	pool.Put(e)
}

// findOrCreate finds the aggregation for a given time, or creates one if it doesn't exist.
// the function returns the lock (shared or exclusive) that was acquired. It is the responsibility of
// the caller to unlock the lock. this allows the caller to continue locking out the flusher until it completes.
func (e *GaugeElem) findOrCreate(
	alignedStart int64,
	createOpts createAggregationOptions,
) (*timedGauge, sync.Locker, error) {
	e.RLock()
	if e.closed {
		e.RUnlock()
		return nil, nil, errElemClosed
	}
	idx, found := e.indexOfWithLock(alignedStart)
	if found {
		return &e.values[idx], e.RWMutex.RLocker(), nil
	}
	e.RUnlock()

	e.Lock()
	if e.closed {
		e.Unlock()
		return nil, nil, errElemClosed
	}
	idx, found = e.indexOfWithLock(alignedStart)
	if found {
		return &e.values[idx], e, nil
	}

	// If not found, create a new aggregation.
	numValues := len(e.values)
	e.values = append(e.values, timedGauge{})
	copy(e.values[idx+1:numValues+1], e.values[idx:numValues])

	var sourcesSeen map[uint32]*bitset.BitSet
	if createOpts.initSourceSet {
		if numCachedSourceSets := len(e.cachedSourceSets); numCachedSourceSets > 0 {
			sourcesSeen = e.cachedSourceSets[numCachedSourceSets-1]
			e.cachedSourceSets[numCachedSourceSets-1] = nil
			e.cachedSourceSets = e.cachedSourceSets[:numCachedSourceSets-1]
			for _, bs := range sourcesSeen {
				bs.ClearAll()
			}
		} else {
			sourcesSeen = make(map[uint32]*bitset.BitSet)
		}
	}
	e.values[idx] = timedGauge{
		startAtNanos:       alignedStart,
		sourcesSeen:        sourcesSeen,
		mu:                 &sync.Mutex{},
		aggregation:        e.NewAggregation(e.opts, e.aggOpts),
		aggValues:          make([]float64, len(e.aggTypes)),
		prevConsumedValues: make([]float64, len(e.aggTypes)),
	}
	return &e.values[idx], e, nil
}

// indexOfWithLock finds the smallest element index whose timestamp
// is no smaller than the start time passed in, and true if it's an
// exact match, false otherwise.
func (e *GaugeElem) indexOfWithLock(alignedStart int64) (int, bool) {
	numValues := len(e.values)
	// Optimize for the common case.
	if numValues > 0 && e.values[numValues-1].startAtNanos == alignedStart {
		return numValues - 1, true
	}
	// Binary search for the unusual case. We intentionally do not
	// use the sort.Search() function because it requires passing
	// in a closure.
	left, right := 0, numValues
	for left < right {
		mid := left + (right-left)/2 // avoid overflow
		if e.values[mid].startAtNanos < alignedStart {
			left = mid + 1
		} else {
			right = mid
		}
	}
	// If the current timestamp is equal to or larger than the target time,
	// return the index as is.
	if left < numValues && e.values[left].startAtNanos == alignedStart {
		return left, true
	}
	return left, false
}

// returns true if a datapoint is emitted.
func (e *GaugeElem) processValueWithAggregationLock(
	timeNanos int64,
	prevTimeNanos int64,
	agg *timedGauge,
	prevAgg *timedGauge,
	flushLocalFn flushLocalMetricFn,
	flushForwardedFn flushForwardedMetricFn,
	resolution time.Duration) bool {
	var (
		transformations  = e.parsedPipeline.Transformations
		discardNaNValues = e.opts.DiscardNaNAggregatedValues()
		emitted          bool
	)
	for aggTypeIdx, aggType := range e.aggTypes {
		var extraDp transformation.Datapoint
		value := agg.aggValues[aggTypeIdx]
		for _, transformOp := range transformations {
			unaryOp, isUnaryOp := transformOp.UnaryTransform()
			binaryOp, isBinaryOp := transformOp.BinaryTransform()
			unaryMultiOp, isUnaryMultiOp := transformOp.UnaryMultiOutputTransform()
			switch {
			case isUnaryOp:
				curr := transformation.Datapoint{
					TimeNanos: int64(timeNanos),
					Value:     value,
				}

				res := unaryOp.Evaluate(curr)

				value = res.Value

			case isBinaryOp:
				var prev transformation.Datapoint
				if prevAgg == nil {
					prev = transformation.Datapoint{
						Value: nan,
					}
				} else {
					prev = transformation.Datapoint{
						TimeNanos: prevTimeNanos,
						Value:     prevAgg.prevConsumedValues[aggTypeIdx],
					}
				}

				curr := transformation.Datapoint{
					TimeNanos: int64(timeNanos),
					Value:     value,
				}
				res := binaryOp.Evaluate(prev, curr, transformation.FeatureFlags{})

				// NB: we only need to record the value needed for derivative transformations.
				// We currently only support first-order derivative transformations so we only
				// need to keep one value. In the future if we need to support higher-order
				// derivative transformations, we need to store an array of values here.
				if !math.IsNaN(curr.Value) {
					agg.prevConsumedValues[aggTypeIdx] = value
				}

				value = res.Value
			case isUnaryMultiOp:
				curr := transformation.Datapoint{
					TimeNanos: int64(timeNanos),
					Value:     value,
				}

				var res transformation.Datapoint
				res, extraDp = unaryMultiOp.Evaluate(curr, resolution)
				value = res.Value
			}
		}

		if discardNaNValues && math.IsNaN(value) {
			continue
		}

		// It's ok to send a 0 prevValue on the first forward because it's not used in AddUnique unless it's a
		// resend (version > 0)
		prevValue := agg.prevConsumedValues[aggTypeIdx]
		agg.prevConsumedValues[aggTypeIdx] = value
		if agg.flushed {
			// no need to resend a value that hasn't changed.
			if (math.IsNaN(prevValue) && math.IsNaN(value)) || (prevValue == value) {
				continue
			}
		}
		emitted = true

		if !e.parsedPipeline.HasRollup {
			toFlush := make([]transformation.Datapoint, 0, 2)
			toFlush = append(toFlush, transformation.Datapoint{
				TimeNanos: int64(timeNanos),
				Value:     value,
			})
			if extraDp.TimeNanos != 0 {
				toFlush = append(toFlush, extraDp)
			}
			for _, point := range toFlush {
				switch e.idPrefixSuffixType {
				case NoPrefixNoSuffix:
					flushLocalFn(nil, e.id, nil, point.TimeNanos, point.Value, agg.annotation, e.sp)
				case WithPrefixWithSuffix:
					flushLocalFn(e.FullPrefix(e.opts), e.id, e.TypeStringFor(e.aggTypesOpts, aggType),
						point.TimeNanos, point.Value, agg.annotation, e.sp)
				}
			}
		} else {
			forwardedAggregationKey, _ := e.ForwardedAggregationKey()
			flushForwardedFn(e.writeForwardedMetricFn, forwardedAggregationKey,
				int64(timeNanos), value, prevValue, agg.annotation)
		}
	}
	return emitted
}
